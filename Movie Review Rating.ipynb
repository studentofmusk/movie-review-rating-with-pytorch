{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf54c157-2f11-4de8-b8e8-1703e5872ce6",
   "metadata": {},
   "source": [
    "# Step 1: Identify and Anonymize PII"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21fd51-40f3-4c76-8aa7-b95b7feec4e5",
   "metadata": {},
   "source": [
    "We'll use a pre-trained NER model from HuggingFace's transformers library to identify PII. For simplicity, we will consider names as PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af4d5b0-42e9-44c7-b397-251dc158c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67cbb335-40c4-4f30-9e01-49b62bb44fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en\n",
    "# Load a pretrained NER model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47062e82-cb1e-4757-bc7d-8db7fdae522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_text(text):\n",
    "    doc = nlp(text)\n",
    "    anonymized_text = text\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PERSON\"]:\n",
    "            anonymized_text = anonymized_text.replace(ent.text, \"[ANONYMIZED]\")\n",
    "    return anonymized_text\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942c698f-3385-4d35-b420-cc91ca892746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANONYMIZED] gave this movie a 5 star rating.\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "text = \"John Doe gave this movie a 5 star rating.\"\n",
    "anonymized_text = anonymize_text(text)\n",
    "print(anonymized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42060e26-a9c8-40ba-8156-4c50c6ce89df",
   "metadata": {},
   "source": [
    "# Step 2: Prepare and Stage Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36135c52-81bc-44ed-8427-6d7869c195df",
   "metadata": {},
   "source": [
    "Assume we have a dataset with movie reviews. We'll split this dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85261ca-b3ff-448e-8fe2-f04b4cf4f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce2ea95-49ff-4452-9559-4c38eda5f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to your dataset\n",
    "data = {\n",
    "    'review': [\n",
    "        \"John loved the movie\", \n",
    "        \"Jane hated the movie\", \n",
    "        \"Alice thought it was okay\", \n",
    "        \"Bob enjoyed the film but thought it was too long\", \n",
    "        \"Charlie was thrilled with the movie's plot\",\n",
    "        \"Dave disliked the acting in the movie\",\n",
    "        \"Eve said the movie was fantastic\",\n",
    "        \"Frank found the movie boring\",\n",
    "        \"Grace thought the movie was well-directed\",\n",
    "        \"Hank was disappointed by the ending\",\n",
    "        \"Ivy loved the cinematography in the movie\",\n",
    "        \"Jack thought the movie was just average\",\n",
    "        \"Karen enjoyed the soundtrack of the movie\",\n",
    "        \"Leo thought the movie was a masterpiece\",\n",
    "        \"Mary said the movie was terrible\",\n",
    "        \"Nina found the movie thrilling\",\n",
    "        \"Oscar thought the movie was too predictable\",\n",
    "        \"Pam loved the character development in the movie\",\n",
    "        \"Quincy disliked the movie's pacing\",\n",
    "        \"Rita said the movie was a visual spectacle\",\n",
    "        \"Sam enjoyed the movie but thought it was a bit slow\",\n",
    "        \"Tina was impressed by the movie's special effects\",\n",
    "        \"Uma thought the movie was poorly written\",\n",
    "        \"Victor loved the movie's action sequences\",\n",
    "        \"Wendy hated the movie's dialogue\",\n",
    "        \"Xander thought the movie was great fun\",\n",
    "        \"Yara found the movie confusing\",\n",
    "        \"Zane thought the movie was overrated\",\n",
    "        \"Amy said the movie was a must-watch\",\n",
    "        \"Bill found the movie to be a waste of time\"\n",
    "    ],\n",
    "    'rating': [\n",
    "        5, 1, 3, 4, 5, \n",
    "        2, 5, 1, 4, 2, \n",
    "        5, 3, 4, 5, 1, \n",
    "        5, 2, 5, 2, 5, \n",
    "        3, 4, 1, 5, 1, \n",
    "        4, 2, 2, 5, 1\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a60304a-f11b-40de-a5cf-7182bcc3bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'review':data['review'],\n",
    "    'rating':data['rating']    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd3a5d9e-9281-4e01-a61b-1d3cf0c95cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John loved the movie</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane hated the movie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice thought it was okay</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob enjoyed the film but thought it was too long</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charlie was thrilled with the movie's plot</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review  rating\n",
       "0                              John loved the movie       5\n",
       "1                              Jane hated the movie       1\n",
       "2                         Alice thought it was okay       3\n",
       "3  Bob enjoyed the film but thought it was too long       4\n",
       "4        Charlie was thrilled with the movie's plot       5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39994d67-f830-4c6e-b708-7e739d8d9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(anonymize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9268c8a6-bbdd-4d0b-8644-816cef66a345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ANONYMIZED] loved the movie</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ANONYMIZED] hated the movie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ANONYMIZED] thought it was okay</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ANONYMIZED] enjoyed the film but thought it w...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ANONYMIZED] was thrilled with the movie's plot</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0                       [ANONYMIZED] loved the movie       5\n",
       "1                       [ANONYMIZED] hated the movie       1\n",
       "2                   [ANONYMIZED] thought it was okay       3\n",
       "3  [ANONYMIZED] enjoyed the film but thought it w...       4\n",
       "4    [ANONYMIZED] was thrilled with the movie's plot       5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da27fd49-0c61-496f-9a42-299b06badffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=.2, random_state=42)\n",
    "# Save the splits\n",
    "train_df.to_csv(\"train_data.csv\", index=False)\n",
    "test_df.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3873ac13-3d86-4832-991b-15d1c620fa82",
   "metadata": {},
   "source": [
    "# Step 3: Train a Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95207d49-cc45-4c43-83d6-3b976a3ba15c",
   "metadata": {},
   "source": [
    "We'll use a simple LSTM-based model in PyTorch for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1444b04-d39f-4bd9-89be-0f00e1635a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e1154b8-7d25-4330-9b15-01d082851cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tokenizer\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6daef452-707c-4d00-a9b0-95aa2b41bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Process the data\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f1aeead-bfc0-48b5-b802-082affe8435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and Train the datasets\n",
    "train_iter = [(row['rating'], row['review']) for _, row in train_df.iterrows()]\n",
    "test_iter = [(row['rating'], row['review']) for _, row in test_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed16ed83-44fc-40af-9048-e6a0fe285618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, '[ANONYMIZED] said the movie was a must-watch'),\n",
       " (1, \"[ANONYMIZED] hated the movie's dialogue\"),\n",
       " (4, '[ANONYMIZED] enjoyed the soundtrack of the movie'),\n",
       " (5, '[ANONYMIZED] loved the movie'),\n",
       " (5, \"[ANONYMIZED] was thrilled with the movie's plot\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aada37b3-6455-4371-a8e4-d5826bb929b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# Text pipeline\n",
    "text_pipeline = lambda x:vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b88d00-64dd-4125-bda4-5ced251c15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataloader\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    return torch.tensor(label_list, dtype=torch.float32), torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True), torch.tensor(lengths,dtype=torch.int64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db4e9d4e-6bdf-42e2-8840-312bd0100e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(to_map_style_dataset(train_iter), batch_size=8, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(to_map_style_dataset(test_iter), batch_size=8, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4ed9168-7c46-41ec-aa54-77bb520fb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1, :, :])\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "845371c9-cd9c-4bc2-84ca-60ed372dffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = LSTMModel(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f487a9b0-acab-47d0-9edc-ac11bc52c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96bd291f-3311-4269-8b43-407dc6daeff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 7.600\n",
      "Epoch 2, Train Loss: 3.364\n",
      "Epoch 3, Train Loss: 4.087\n",
      "Epoch 4, Train Loss: 2.361\n",
      "Epoch 5, Train Loss: 2.623\n",
      "Epoch 6, Train Loss: 2.660\n",
      "Epoch 7, Train Loss: 2.080\n",
      "Epoch 8, Train Loss: 1.935\n",
      "Epoch 9, Train Loss: 1.930\n",
      "Epoch 10, Train Loss: 1.902\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for labels, texts, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        labels, texts, lengths = labels.to(device), texts.to(device), lengths.to(device)\n",
    "        predictions = model(texts, lengths).squeeze(1)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edcd7a8a-572e-46fd-b5a6-86e3faf21cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Zane thought the movie was overrated'),\n",
       " (5, 'Nina found the movie thrilling'),\n",
       " (5, \"Victor loved the movie's action sequences\"),\n",
       " (5, 'Pam loved the character development in the movie'),\n",
       " (4, 'Grace thought the movie was well-directed'),\n",
       " (2, '[ANONYMIZED] was disappointed by the ending')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d1816ea-1b34-43f7-a992-f8bd1ebfe5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess new data\n",
    "def preprocess(text, tokenizer, vocab):\n",
    "    tokens = tokenizer(text)\n",
    "    token_indices = [vocab[token] for token in tokens]\n",
    "    return token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "273c7ae2-9041-48ac-b92e-a1e8dcec8534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 49]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Farooq said okay\", tokenizer, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "feaf4178-2e92-4eaa-b920-1f4c9a2c0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for do predictions\n",
    "def predict (text, model, tokenizer, vocab, device):\n",
    "    model.eval()\n",
    "    token_indices = preprocess(text, tokenizer, vocab)\n",
    "    text_tensor = torch.tensor([token_indices], dtype=torch.int64, device=device)\n",
    "    text_length = torch.tensor([len(token_indices)], dtype=torch.int64, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(text_tensor, text_length)\n",
    "    return output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c83027f6-a119-4e9b-9f50-275a665b3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I loved the movie, it was fantastic!\n",
      "Predicted Rating: 3.66\n",
      "Review: The film was terrible, I hated it.\n",
      "Predicted Rating: 2.43\n",
      "Review: worst movie\n",
      "Predicted Rating: 1.24\n"
     ]
    }
   ],
   "source": [
    "# Example new data\n",
    "new_reviews = [\n",
    "    \"I loved the movie, it was fantastic!\",\n",
    "    \"The film was terrible, I hated it.\",\n",
    "    \"worst movie\"\n",
    "]\n",
    "\n",
    "# Make predictions\n",
    "for review in new_reviews:\n",
    "    prediction = predict(review, model, tokenizer, vocab, device)\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted Rating: {prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a79e8-f02e-4c8c-bcc0-fa39a215f42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd8437-d94a-478a-83ac-5eb34753449d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
